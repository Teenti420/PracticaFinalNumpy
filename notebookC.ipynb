{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Gov 10a exp page linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la lectura de todos los registros del data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este conjunto de datos tiene un total de  282  registros\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/gov_10a_exp_page_linear.csv', delimiter=',', skiprows=1, dtype=[('DATAFLOW', np.unicode_, 50), ('LAST UPDATE', np.unicode_, 40), ('freq', np.unicode_, 12), ('unit', np.unicode_, 12), ('sector', np.unicode_, 12), ('cofog99', np.unicode_, 12), ('na_item', np.unicode_, 12), ('geo', np.unicode_, 12), ('TIME_PERIOD', 'i4'), ('OBS_VALUE', 'f4'), ('OBS_FLAG', np.unicode_, 12)])\n",
    "print(\"Este conjunto de datos tiene un total de \", data.shape[0], \" registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ESTAT:GOV_10A_EXP$DEFAULTVIEW(1.0)', '03/01/23 11:00:00', 'A', 'PC_GDP', 'S13', 'TOTAL', 'TE', 'AT', 2012, 51.2, '')\n",
      " ('ESTAT:GOV_10A_EXP$DEFAULTVIEW(1.0)', '03/01/23 11:00:00', 'A', 'PC_GDP', 'S13', 'TOTAL', 'TE', 'AT', 2013, 51.6, '')\n",
      " ('ESTAT:GOV_10A_EXP$DEFAULTVIEW(1.0)', '03/01/23 11:00:00', 'A', 'PC_GDP', 'S13', 'TOTAL', 'TE', 'AT', 2014, 52.4, '')\n",
      " ('ESTAT:GOV_10A_EXP$DEFAULTVIEW(1.0)', '03/01/23 11:00:00', 'A', 'PC_GDP', 'S13', 'TOTAL', 'TE', 'AT', 2015, 51.1, '')\n",
      " ('ESTAT:GOV_10A_EXP$DEFAULTVIEW(1.0)', '03/01/23 11:00:00', 'A', 'PC_GDP', 'S13', 'TOTAL', 'TE', 'AT', 2016, 50.1, '')]\n"
     ]
    }
   ],
   "source": [
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el dataset en nuestro local storage vamos a realizar un pequeño estudio sobre los datos para ver que es lo que podemos sacar de ellos.\n",
    "\n",
    "Primero de todos vamos a ver cuantos registros diferentes hay de cada una de las columnas, ya que a primera vista parece que tenemos muchas variables con un solo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De la variable freq tenemos un total de  1  registros diferentes\n",
      "De la variable DATAFLOW tenemos un total de  1  registros diferentes\n",
      "De la variable LAST UPDATE tenemos un total de  1  registros diferentes\n",
      "De la variable unit tenemos un total de  1  registros diferentes\n",
      "De la variable sector tenemos un total de  1  registros diferentes\n",
      "De la variable cofog99 tenemos un total de  1  registros diferentes\n",
      "De la variable geo tenemos un total de  31  registros diferentes\n",
      "De la variable na_item tenemos un total de  1  registros diferentes\n",
      "De la variable TIME_PERIOD tenemos un total de  10  registros diferentes\n",
      "De la variable OBS_FLAG tenemos un total de  3  registros diferentes\n"
     ]
    }
   ],
   "source": [
    "print(\"De la variable freq tenemos un total de \", np.unique(data['freq']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable DATAFLOW tenemos un total de \", np.unique(data['DATAFLOW']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable LAST UPDATE tenemos un total de \", np.unique(data['LAST UPDATE']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable unit tenemos un total de \", np.unique(data['unit']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable sector tenemos un total de \", np.unique(data['sector']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable cofog99 tenemos un total de \", np.unique(data['cofog99']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable geo tenemos un total de \", np.unique(data['geo']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable na_item tenemos un total de \", np.unique(data['na_item']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable TIME_PERIOD tenemos un total de \", np.unique(data['TIME_PERIOD']).shape[0], \" registros diferentes\")\n",
    "print(\"De la variable OBS_FLAG tenemos un total de \", np.unique(data['OBS_FLAG']).shape[0], \" registros diferentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto solo nos interesaran los registros geo, TIME_PERIOD y OBS_FLAG, ya que los otros registros no podrán darnos ninguna información sobre los datos.\n",
    "\n",
    "Vamos a empezar a trabajar con la variable **geo** que se refiere a la zona. Primero de todo vamos a obtener los registros únicos que tenemos y realizar una agrupación de esta para obtener información sobre el **OBS_VALUE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = data['geo']\n",
    "geonames, indices = np.unique(geo, return_inverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AT' 'BE' 'BG' 'CY' 'CZ' 'DE' 'DK' 'EA19' 'EE' 'EL' 'ES' 'EU27_2020' 'FI'\n",
      " 'FR' 'HR' 'HU' 'IE' 'IS' 'IT' 'LT' 'LU' 'LV' 'MT' 'NL' 'NO' 'PL' 'PT'\n",
      " 'RO' 'SE' 'SI' 'SK']\n"
     ]
    }
   ],
   "source": [
    "print(geonames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([515.79999542, 490.19999695, 339.5       , 375.40000153,\n",
       "       379.59999847, 406.90000153, 531.        , 439.70000458,\n",
       "       358.20000839, 478.90000153, 403.30000305, 436.40000153,\n",
       "       499.29999542, 514.09999847, 431.20000458, 436.39999771,\n",
       "       280.99999809, 411.40000153, 454.69999695, 320.80000305,\n",
       "       377.5       , 351.5       , 350.00000381, 449.59999084,\n",
       "       444.19999695, 384.79999542, 423.90000534, 324.20000076,\n",
       "       452.70000076, 437.59999847, 381.39999771])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizamos la suma del OBS_VALUE por zona\n",
    "np.bincount(indices, data['OBS_VALUE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función anterior no nos ha dado mucha información sobre los datos, creo que sería mejor obtener la media y la mediana por zona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = data['geo']\n",
    "countries_obsVal = [(i, round(data['OBS_VALUE'][countries == i].mean(), 2)) for i in geonames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mediana del OBS_VALUE por zona es:\n",
      " [('AT', 51.58), ('BE', 54.47), ('BG', 37.72), ('CY', 41.71), ('CZ', 42.18), ('DE', 45.21), ('DK', 53.1), ('EA19', 48.86), ('EE', 39.8), ('EL', 53.21), ('ES', 44.81), ('EU27_2020', 48.49), ('FI', 55.48), ('FR', 57.12), ('HR', 47.91), ('HU', 48.49), ('IE', 31.22), ('IS', 45.71), ('IT', 50.52), ('LT', 35.64), ('LU', 41.94), ('LV', 39.06), ('MT', 38.89), ('NL', 44.96), ('NO', 49.36), ('PL', 42.76), ('PT', 47.1), ('RO', 36.02), ('SE', 50.3), ('SI', 48.62), ('SK', 42.38)]\n"
     ]
    }
   ],
   "source": [
    "print(\"La mediana del OBS_VALUE por zona es:\\n\", countries_obsVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a realizar una ordenación sobre estos datos\n",
    "countries_obsVal = np.array(countries_obsVal, dtype=[('geo', np.unicode_, 12), ('OBS_VALUE', np.float64)])\n",
    "countries_obsVal_Asc = np.sort(countries_obsVal, order='OBS_VALUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordenación ascendente (head):  [('IE', 31.21999931) ('LT', 35.63999939) ('RO', 36.02000046)\n",
      " ('BG', 37.72000122) ('MT', 38.88999939)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ordenación ascendente (head): \", countries_obsVal_Asc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordenación ascendente (tail):  [('DK', 53.09999847) ('EL', 53.20999908) ('BE', 54.47000122)\n",
      " ('FI', 55.47999954) ('FR', 57.11999893)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ordenación ascendente (tail): \", countries_obsVal_Asc[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por tanto, según la ordenación anterior la zona con el OBS_VALUE más pequeño es  IE con un valor medio de  31.22\n",
      "Por otra partem la zona con un OBS_VALUE mayor es  FR  con un valor medio de  57.12\n"
     ]
    }
   ],
   "source": [
    "print(\"Por tanto, según la ordenación anterior la zona con el OBS_VALUE más pequeño es \", countries_obsVal_Asc[:1][0][0], \"con un valor medio de \", round(countries_obsVal_Asc[:1][0][1], 2))\n",
    "print(\"Por otra partem la zona con un OBS_VALUE mayor es \", countries_obsVal_Asc[-1:][0][0], \" con un valor medio de \", round(countries_obsVal_Asc[-1:][0][1], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver que tal el valor de la zona de España, abreviada como 'ES'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor del OBS_VALUE en españa se encuentra en  [('ES', 44.81000137)]\n"
     ]
    }
   ],
   "source": [
    "espana = 'ES'\n",
    "mask = countries_obsVal['geo'] == espana\n",
    "print(\"El valor del OBS_VALUE en españa se encuentra en \", countries_obsVal[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a empezar a trabajar con los años, **TIME_PERIOD**. Vamos a ver si hay algún tipo de relación entre el **TIME_PERIOD** y el **OBS_VALUE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsValueByGeoAndPeriod = data[['geo', 'TIME_PERIOD', 'OBS_VALUE', 'OBS_FLAG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como vemos, según el muestreo, estos son los cinco registros con un valor de OBS_VALUE menor:\n",
      " [('IE', 2019, 24.2, '') ('IE', 2018, 25.3, '') ('IE', 2017, 26.2, '')\n",
      " ('IE', 2020, 27.4, '') ('IE', 2016, 28.1, '')]\n",
      "Los mayores son:\n",
      " [('BE', 2020, 59.2, '') ('EL', 2020, 59.8, '') ('SI', 2013, 60.3, '')\n",
      " ('FR', 2020, 61.6, 'p') ('EL', 2013, 62.8, '')]\n"
     ]
    }
   ],
   "source": [
    "obsValuePeriodOrdAsc = np.sort(obsValueByGeoAndPeriod, order='OBS_VALUE')\n",
    "print(\"Como vemos, según el muestreo, estos son los cinco registros con un valor de OBS_VALUE menor:\\n\", obsValuePeriodOrdAsc[:5])\n",
    "print(\"Los mayores son:\\n\", obsValuePeriodOrdAsc[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizaremos la agrupación por año y obtendremos la media y la desviación típica del OBS_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, idx = np.unique(obsValueByGeoAndPeriod[\"TIME_PERIOD\"], return_inverse=True)\n",
    "time_period = obsValueByGeoAndPeriod[\"TIME_PERIOD\"]\n",
    "year_obsVal_mean = np.array([(i, np.mean((obsValueByGeoAndPeriod['OBS_VALUE'][time_period == i]))) for i in tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mediana del OBS_VALUE de cada año registrado es:\n",
      " [[2012.           46.64516449]\n",
      " [2013.           47.06774139]\n",
      " [2014.           46.56452179]\n",
      " [2015.           45.53225327]\n",
      " [2016.           44.23225784]\n",
      " [2017.           43.34516144]\n",
      " [2018.           43.60000229]\n",
      " [2019.           43.49354935]\n",
      " [2020.           50.09354401]\n",
      " [2021.           51.1333313 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"La mediana del OBS_VALUE de cada año registrado es:\\n\", year_obsVal_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La desviación típica del OBS_VALUE de cada año registrado es:\n",
      " [[2012.            6.33499479]\n",
      " [2013.            7.0906291 ]\n",
      " [2014.            6.14893436]\n",
      " [2015.            6.54642916]\n",
      " [2016.            6.75513554]\n",
      " [2017.            6.72917843]\n",
      " [2018.            6.27293205]\n",
      " [2019.            6.38460541]\n",
      " [2020.            6.85141563]\n",
      " [2021.            3.84476614]]\n"
     ]
    }
   ],
   "source": [
    "year_obsVal_std = np.array([(i, np.std((obsValueByGeoAndPeriod['OBS_VALUE'][time_period == i]))) for i in tp])\n",
    "print(\"La desviación típica del OBS_VALUE de cada año registrado es:\\n\", year_obsVal_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL mínimo valor medio de los años del df es  43.35  que se encuentra en el  2017\n",
      "El máximo OBS_VALUE se encuentra en el año  2021  con un valor del OBS_VALUE de  51.13  de media\n"
     ]
    }
   ],
   "source": [
    "print(\"EL mínimo valor medio de los años del df es \", round(year_obsVal_mean[:,1].min(), 2), \" que se encuentra en el \", int(year_obsVal_mean[year_obsVal_mean[:,1].argmin()][0]))\n",
    "print(\"El máximo OBS_VALUE se encuentra en el año \", int(year_obsVal_mean[year_obsVal_mean[:,1].argmax()][0]), \" con un valor del OBS_VALUE de \", round(year_obsVal_mean[:,1].max(), 2), \" de media\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "d98aac1e535e903778b997b951760c462bbbaee0c80758d126e1de8ea64aebe1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
